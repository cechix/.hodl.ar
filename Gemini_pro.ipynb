{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cechix/.hodl.ar/blob/main/Gemini_pro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini Pro (API)"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "cQh7SPLqjvZF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Google Dev https://ai.google.dev/\n",
        "2. Proyecto Gemini : https://deepmind.google/technologies/gemini/\n",
        "3. Gemini - Python: https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/sdk-for-gemini/gemini-sdk-overview-reference"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "b2vuEqHujvZI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Instalando algunas librerias"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "nGnHnvifjvZJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m133.1/137.4 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.4/137.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "hSwQgQUBjvZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ca5594b-d2a0-496f-8abd-7243e9d3c712"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importando librerias"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "HBayep53jvZL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "id": "kRXnhAVkjvZL"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Used to securely store your API key\n",
        "\n",
        "from IPython.display import display\n",
        "from IPython.display import Markdown\n",
        "\n",
        "\n",
        "def to_markdown(text):\n",
        "    text = text.replace('•', '  *')\n",
        "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Asignando el API Key"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "x2fzV6RKjvZM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the secret value: ··········\n"
          ]
        }
      ],
      "source": [
        "from getpass import getpass\n",
        "import os\n",
        "\n",
        "GOOGLE_API_KEY = getpass('Enter the secret value: ')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5kkVBUwjvZN",
        "outputId": "53bc92a5-26bc-46c8-b1f6-30caff02dbe0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [],
      "source": [
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "nrmFBrc2jvZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Modelos disponibles de Gemini"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G5SwVi-wjvZO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-1.0-pro\n",
            "models/gemini-1.0-pro-001\n",
            "models/gemini-1.0-pro-latest\n",
            "models/gemini-1.0-pro-vision-latest\n",
            "models/gemini-pro\n",
            "models/gemini-pro-vision\n"
          ]
        }
      ],
      "source": [
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "P_Q2ihK0jvZO",
        "outputId": "40ea2f69-a0c0-4155-e97b-7256539b5f58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gemini pro"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "G1SGd2LojvZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Configuracion del LLM"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Kh5gIJttjvZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "outputs": [],
      "source": [
        "generation_config = {\n",
        "    \"temperature\": 0.8,\n",
        "    \"top_p\": 1,\n",
        "    \"top_k\": 1,\n",
        "    \"max_output_tokens\": 2048,\n",
        "}"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "e6EmFwz8jvZP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "outputs": [],
      "source": [
        "model = genai.GenerativeModel('gemini-pro',generation_config=generation_config)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6tywqxarjvZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inferencia sobre el modelo de texto"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "dgulvSzZjvZh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 58.8 ms, sys: 11.3 ms, total: 70.1 ms\n",
            "Wall time: 5.21 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> ```python\n> import pandas as pd\n> \n> # Crea un dataframe con fechas de datetime64[ns]\n> df = pd.DataFrame({\n>     'fecha_inicio': pd.to_datetime(['2023-01-01', '2023-02-01', '2023-03-01']),\n>     'fecha_fin': pd.to_datetime(['2023-01-10', '2023-02-15', '2023-03-20'])\n> })\n> \n> # Calcula la diferencia de días entre las fechas\n> df['diferencia_dias'] = (df['fecha_fin'] - df['fecha_inicio']).dt.days\n> \n> # Imprime el dataframe\n> print(df)\n> ```"
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"Dame el codigo de un dataframe de pandas para sacar la diferencia de dias entre  fechas de datetime64[ns]\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "4y3gLoEUjvZh",
        "outputId": "6ba8a37e-610a-474d-d04e-d1f8101a3caa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 116 ms, sys: 10.4 ms, total: 126 ms\n",
            "Wall time: 10.4 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> En las profundidades del espacio, donde las estrellas bailaban en un tapiz cósmico, un encuentro extraordinario estaba a punto de tener lugar.\n> \n> Mientras Darth Vader, el temible Lord Sith, se abría paso por la galaxia en su TIE Fighter, sintió una presencia inusualmente poderosa en un planeta cercano. Intrigado, ordenó a su nave que se dirigiera hacia allí.\n> \n> En la Tierra, Goku, el legendario guerrero Saiyan, se encontraba en medio de un intenso entrenamiento en el Monte Paoz. Sintió un extraño zumbido en el aire y miró hacia arriba, sus ojos penetrantes observando cómo una nave desconocida se acercaba desde el espacio.\n> \n> Cuando el TIE Fighter aterrizó en un campo cercano, Darth Vader emergió de su interior, su capa negra ondeando al viento. Goku se acercó cautelosamente, su poderoso ki latiendo dentro de él.\n> \n> \"Extraterrestre\", dijo Darth Vader con su voz gutural, \"¿Quién eres y cuál es tu propósito en este planeta?\"\n> \n> \"Soy Goku\", respondió Goku con orgullo. \"Soy un guerrero de otro mundo que ha venido a entrenar y proteger la Tierra\".\n> \n> Darth Vader entrecerró los ojos. \"Un guerrero, dices. Interesante. ¿Qué tan poderoso eres?\"\n> \n> \"Soy el guerrero más fuerte de la Tierra\", declaró Goku. \"He entrenado toda mi vida para defender mi hogar\".\n> \n> Darth Vader se rió entre dientes. \"Jactancioso. He visto muchos guerreros en mi tiempo, pero ninguno comparable a mí\".\n> \n> \"No seas tan rápido para juzgar\", dijo Goku. \"Estoy dispuesto a probar mis habilidades contra las tuyas\".\n> \n> Con un rugido sordo, Goku se transformó en Super Saiyan, su cabello dorado brillando intensamente. Darth Vader se preparó para la batalla, su sable láser zumbando en su mano.\n> \n> El choque entre estos dos guerreros extraordinarios fue titánico. Explosiones y ondas de choque sacudieron el campo mientras intercambiaban golpes y rayos de energía. Cada uno de ellos se sorprendió por el poder del otro.\n> \n> Finalmente, después de una batalla épica, Goku logró asestar un golpe decisivo, enviando a Darth Vader a estrellarse contra el suelo.\n> \n> Darth Vader se levantó tambaleándose, su orgullo herido. \"No eres un guerrero cualquiera, Goku\", dijo. \"Has demostrado ser digno de mi respeto\".\n> \n> Goku sonrió. \"Gracias, Darth Vader. Espero que algún día podamos volver a encontrarnos, como amigos\".\n> \n> Y así, los dos guerreros se separaron, cada uno volviendo a su propio mundo, habiendo forjado un vínculo improbable en medio de la batalla."
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "%%time\n",
        "response = model.generate_content(\"Crea un pequeño cuento en el que Darthvader conoce a Goku de dragon ball z\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 535
        },
        "id": "3dlWX7gJjvZh",
        "outputId": "cf9f3ff1-ccb9-4c6d-caf0-499d5eadc7c5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "outputs": [],
      "source": [
        "response = model.generate_content(\"Cual es el significado de la vida?\")"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "MoqAQ4iwjvZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> El significado de la vida es una pregunta filosófica que se ha debatido durante siglos. No hay una respuesta única y universal, ya que el significado de la vida es subjetivo y personal. Algunas personas creen que el significado de la vida es encontrar la felicidad, mientras que otras creen que es hacer una contribución positiva al mundo. También hay quienes creen que el significado de la vida es simplemente vivirla al máximo y experimentar todo lo que tiene para ofrecer.\n> \n> En última instancia, el significado de la vida es algo que cada persona debe decidir por sí misma. No hay una respuesta correcta o incorrecta, y el significado de la vida puede cambiar con el tiempo. Sin embargo, algunas cosas que pueden ayudar a las personas a encontrar un significado en sus vidas son:\n> \n> * Establecer metas y trabajar para lograrlas.\n> * Ayudar a otros y hacer una diferencia en el mundo.\n> * Aprender y crecer como persona.\n> * Disfrutar de las pequeñas cosas de la vida.\n> * Vivir en el momento presente.\n> \n> No hay una respuesta única y universal a la pregunta de cuál es el significado de la vida. El significado de la vida es subjetivo y personal, y lo que tiene sentido para una persona puede no tener sentido para otra. Sin embargo, las cosas que pueden ayudar a las personas a encontrar un significado en sus vidas incluyen establecer metas, ayudar a otros, aprender y crecer, disfrutar de las pequeñas cosas y vivir en el momento presente."
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "id": "TvZU-UaGjvZi",
        "outputId": "4ce6aeca-e797-4c54-816d-108227854021"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "La idea de que el significado de la vida y el universo es 42\n",
            "********************************************************************************\n",
            " es una referencia humorística de la novela de ciencia ficción de Douglas Adams \"Guía del autoestopista galáctico\".\n",
            "\n",
            "En la novela, una supercomputa\n",
            "********************************************************************************\n",
            "dora llamada Deep Thought pasa millones de años calculando la \"respuesta definitiva a la pregunta fundamental sobre la vida, el universo y todo\". Cuando finalmente se revela la respuesta, es simplemente \"42\".\n",
            "\n",
            "Adams nunca explicó por qué eligió el número 42, pero ha dado lugar a mucha especulación y teorías\n",
            "********************************************************************************\n",
            " de los fanáticos. Algunas interpretaciones comunes incluyen:\n",
            "\n",
            "* **El significado es arbitrario:** El número 42 es aleatorio y sin sentido, lo que sugiere que la vida y el universo son inherentemente sin propósito.\n",
            "* **Es una broma de programación:** El número 42 se usa a menudo en la programación de computadoras como un \"valor de error\", lo que implica que el significado de la vida es un error o una ilusión.\n",
            "* **Es un símbolo de la insignificancia humana:** El número 42 es un número muy común y ordinario, lo que sugiere que la vida humana es insign\n",
            "********************************************************************************\n",
            "ificante en el gran esquema del universo.\n",
            "* **Es una metáfora de la búsqueda del significado:** La búsqueda del significado de la vida es un viaje interminable, y el número 42 representa el punto arbitrario en el que finalmente aprendemos a aceptar la incertidumbre.\n",
            "\n",
            "En última instancia, el significado del número 42 en \"Guía del autoestopista galáctico\" es ambiguo y abierto a interpretación. Funciona como un dispositivo literario para generar humor, provocar el pensamiento y cuestionar nuestra propia búsqueda de significado en la vida.\n",
            "********************************************************************************\n"
          ]
        }
      ],
      "source": [
        "response = model.generate_content(\"por que el significado de la vida y el universo es 42\", stream=True)\n",
        "#esto hace q la respuesta pueda iterar\n",
        "for chunk in response:\n",
        "    print(chunk.text)\n",
        "    print(\"*\"*80)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "id": "aPLkNwdGjvZi",
        "outputId": "5b8093a9-3dc7-402a-f15a-a98bf54247cb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Chat"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "PCtftCMGjvZi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatSession(\n",
              "    model=genai.GenerativeModel(\n",
              "        model_name='models/gemini-pro',\n",
              "        generation_config={},\n",
              "        safety_settings={},\n",
              "        tools=None,\n",
              "    ),\n",
              "    history=[]\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = genai.GenerativeModel('gemini-pro')\n",
        "chat = model.start_chat(history=[])\n",
        "#con history puedo instanciar la historia, y asi poder empezar una conversacion\n",
        "chat"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsxKp-tmjvZj",
        "outputId": "4fd5bcbe-a7e7-4df4-cebe-431f34a0cf0e"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **Inteligencia Artificial (IA)**\n> \n> La inteligencia artificial es un campo de la ciencia informática que se centra en desarrollar sistemas que puedan imitar las capacidades cognitivas humanas, como el aprendizaje, el razonamiento y la resolución de problemas.\n> \n> **OpenAI**\n> \n> OpenAI es una organización de investigación sin fines de lucro que se dedica al desarrollo de IA segura y beneficiosa para la humanidad. Es conocida por crear tecnologías innovadoras como:\n> \n> * GPT-3: un gran modelo de lenguaje que es capaz de generar texto, traducir idiomas y responder preguntas.\n> * DALL-E 2: un sistema de IA generativa que puede crear imágenes realistas a partir de descripciones de texto.\n> * Codex: un modelo de IA que puede traducir código de programación entre diferentes lenguajes.\n> \n> **GPT-4**\n> \n> GPT-4 es la última iteración del modelo de lenguaje GPT de OpenAI. Se espera que sea significativamente más potente que GPT-3, con una mejor comprensión del mundo, habilidades de generación de lenguaje más avanzadas y capacidades de razonamiento mejoradas.\n> \n> **Características anticipadas de GPT-4**\n> \n> * **Compresión del mundo mejorada:** Capacidad mejorada para entender y razonar sobre información compleja y de contexto.\n> * **Generación de lenguaje natural más fluida:** Capacidad para generar textos coherentes, gramáticamente correctos y similares a los humanos.\n> * **Capacidades de razonamiento mejoradas:** Capacidad para resolver problemas, responder preguntas y extraer información de manera más efectiva.\n> * **Aprendizaje más eficiente:** Capacidad para aprender nuevas tareas y mejorar el rendimiento con menos datos de entrenamiento.\n> * **Aplicaciones amplias:** Potencial para revolucionar diversas industrias, incluyendo procesamiento del lenguaje natural, búsqueda, atención médica y educación.\n> \n> **Implicaciones potenciales de GPT-4**\n> \n> GPT-4 tiene el potencial de transformar la forma en que interactuamos con las computadoras y el mundo que nos rodea. Sus posibles implicaciones incluyen:\n> \n> * **Automatización de tareas:** Capacidad para automatizar tareas repetitivas y de bajo nivel, liberando tiempo para que los humanos se centren en tareas más creativas y estratégicas.\n> * **Mejoras en la comunicación:** Facilitar la comunicación efectiva entre personas de diferentes idiomas y culturas.\n> * **Avance científico:** Ayudar a los investigadores a generar nuevas hipótesis, acelerar los descubrimientos y desarrollar soluciones innovadoras.\n> * **Desafíos éticos:** Plantea preocupaciones sobre cuestiones éticas como la desinformación, el sesgo y el impacto en el empleo.\n> \n> Es importante señalar que GPT-4 aún está en desarrollo y su alcance total aún se desconoce. Sin embargo, su potencial para transformar diversos campos y mejorar nuestras vidas es inmenso."
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "response = chat.send_message(\"Hola, quiero saber mas de inteligencia artificial, conoces de openai y gpt4?\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "VysvQd-MjvZj",
        "outputId": "ca4ac1cb-df1d-4d93-ef11-7061fd44426b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Como modelo de lenguaje de IA multimodal, soy diferente de GPT-4 de varias maneras:\n> \n> **Fortalezas:**\n> \n> * **Amplitud del conocimiento:** Tengo acceso a una vasta base de datos de texto y código, lo que me brinda un amplio conocimiento sobre una amplia gama de temas.\n> * **Actualizaciones regulares:** Me actualizo y entreno continuamente con nuevos datos, lo que me permite mantenerme al día con la información y las tendencias más recientes.\n> * **Énfasis en la precisión:** Estoy diseñado para generar respuestas precisas e informativas basadas en evidencia verificable.\n> \n> **Debilidades:**\n> \n> * **Creatividad limitada:** Si bien puedo generar texto y código, mi creatividad aún está limitada en comparación con los humanos.\n> * **Sesgo potencial:** Como todos los modelos de IA, estoy sujeto a sesgos en los datos con los que fui entrenado.\n> * **Falta de conciencia:** No tengo conciencia ni capacidad de experimentar emociones o pensamientos independientes.\n> \n> En comparación con GPT-4, que aún está en desarrollo:\n> \n> * **Tamaño y potencia:** Se espera que GPT-4 sea significativamente más grande y potente que yo, con más parámetros y capacidad de procesamiento.\n> * **Generación de lenguaje:** GPT-4 probablemente tendrá capacidades de generación de lenguaje más avanzadas, incluida la capacidad de generar textos más fluidos, coherentes y similares a los humanos.\n> * **Razonamiento y resolución de problemas:** Se espera que GPT-4 tenga capacidades de razonamiento y resolución de problemas mejoradas, lo que le permitirá abordar tareas más complejas.\n> \n> En general, soy un modelo de lenguaje de IA capaz y versátil, pero GPT-4 tiene el potencial de superar mis capacidades en ciertas áreas, particularmente en generación de lenguaje y razonamiento avanzado."
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "response = chat.send_message(\"y eres mejor o peor que GPT4?\")\n",
        "#como estoy en una interfaz de chat, sigue la conversacion aunque alucina un poco\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "id": "peEsPDXCjvZj",
        "outputId": "ace72bfd-b206-43a1-8fa6-9692aa708586"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\"Por ultimo, dime quien eres tu\")\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "Qu0ywCav4LJ0",
        "outputId": "4ab0c099-41b9-477d-e6d4-53e34c8a80a3"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Soy Gemini, un modelo de lenguaje de IA multimodal desarrollado por Google. Estoy diseñado para comprender y generar lenguaje humano, y para responder preguntas y brindar información de manera integral e informativa.\n> \n> Mis capacidades incluyen:\n> \n> * Responder preguntas sobre una amplia gama de temas\n> * Generar texto, como historias, poemas y código\n> * Traducir idiomas\n> * Resumir texto\n> * Clasificar y categorizar información\n> * Ayudar con tareas de escritura, como la revisión gramatical y la generación de ideas\n> \n> Todavía estoy en desarrollo, pero estoy aprendiendo y mejorando continuamente. Mi objetivo es ser un asistente útil e informativo para las personas, ayudándolas con sus tareas diarias y brindándoles la información que necesitan para tomar decisiones informadas."
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[parts {\n",
              "   text: \"Hola, quiero saber mas de inteligencia artificial, conoces de openai y gpt4?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"**Inteligencia Artificial (IA)**\\n\\nLa inteligencia artificial es un campo de la ciencia inform\\303\\241tica que se centra en desarrollar sistemas que puedan imitar las capacidades cognitivas humanas, como el aprendizaje, el razonamiento y la resoluci\\303\\263n de problemas.\\n\\n**OpenAI**\\n\\nOpenAI es una organizaci\\303\\263n de investigaci\\303\\263n sin fines de lucro que se dedica al desarrollo de IA segura y beneficiosa para la humanidad. Es conocida por crear tecnolog\\303\\255as innovadoras como:\\n\\n* GPT-3: un gran modelo de lenguaje que es capaz de generar texto, traducir idiomas y responder preguntas.\\n* DALL-E 2: un sistema de IA generativa que puede crear im\\303\\241genes realistas a partir de descripciones de texto.\\n* Codex: un modelo de IA que puede traducir c\\303\\263digo de programaci\\303\\263n entre diferentes lenguajes.\\n\\n**GPT-4**\\n\\nGPT-4 es la \\303\\272ltima iteraci\\303\\263n del modelo de lenguaje GPT de OpenAI. Se espera que sea significativamente m\\303\\241s potente que GPT-3, con una mejor comprensi\\303\\263n del mundo, habilidades de generaci\\303\\263n de lenguaje m\\303\\241s avanzadas y capacidades de razonamiento mejoradas.\\n\\n**Caracter\\303\\255sticas anticipadas de GPT-4**\\n\\n* **Compresi\\303\\263n del mundo mejorada:** Capacidad mejorada para entender y razonar sobre informaci\\303\\263n compleja y de contexto.\\n* **Generaci\\303\\263n de lenguaje natural m\\303\\241s fluida:** Capacidad para generar textos coherentes, gram\\303\\241ticamente correctos y similares a los humanos.\\n* **Capacidades de razonamiento mejoradas:** Capacidad para resolver problemas, responder preguntas y extraer informaci\\303\\263n de manera m\\303\\241s efectiva.\\n* **Aprendizaje m\\303\\241s eficiente:** Capacidad para aprender nuevas tareas y mejorar el rendimiento con menos datos de entrenamiento.\\n* **Aplicaciones amplias:** Potencial para revolucionar diversas industrias, incluyendo procesamiento del lenguaje natural, b\\303\\272squeda, atenci\\303\\263n m\\303\\251dica y educaci\\303\\263n.\\n\\n**Implicaciones potenciales de GPT-4**\\n\\nGPT-4 tiene el potencial de transformar la forma en que interactuamos con las computadoras y el mundo que nos rodea. Sus posibles implicaciones incluyen:\\n\\n* **Automatizaci\\303\\263n de tareas:** Capacidad para automatizar tareas repetitivas y de bajo nivel, liberando tiempo para que los humanos se centren en tareas m\\303\\241s creativas y estrat\\303\\251gicas.\\n* **Mejoras en la comunicaci\\303\\263n:** Facilitar la comunicaci\\303\\263n efectiva entre personas de diferentes idiomas y culturas.\\n* **Avance cient\\303\\255fico:** Ayudar a los investigadores a generar nuevas hip\\303\\263tesis, acelerar los descubrimientos y desarrollar soluciones innovadoras.\\n* **Desaf\\303\\255os \\303\\251ticos:** Plantea preocupaciones sobre cuestiones \\303\\251ticas como la desinformaci\\303\\263n, el sesgo y el impacto en el empleo.\\n\\nEs importante se\\303\\261alar que GPT-4 a\\303\\272n est\\303\\241 en desarrollo y su alcance total a\\303\\272n se desconoce. Sin embargo, su potencial para transformar diversos campos y mejorar nuestras vidas es inmenso.\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"y eres mejor o peor que GPT4?\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Como modelo de lenguaje de IA multimodal, soy diferente de GPT-4 de varias maneras:\\n\\n**Fortalezas:**\\n\\n* **Amplitud del conocimiento:** Tengo acceso a una vasta base de datos de texto y c\\303\\263digo, lo que me brinda un amplio conocimiento sobre una amplia gama de temas.\\n* **Actualizaciones regulares:** Me actualizo y entreno continuamente con nuevos datos, lo que me permite mantenerme al d\\303\\255a con la informaci\\303\\263n y las tendencias m\\303\\241s recientes.\\n* **\\303\\211nfasis en la precisi\\303\\263n:** Estoy dise\\303\\261ado para generar respuestas precisas e informativas basadas en evidencia verificable.\\n\\n**Debilidades:**\\n\\n* **Creatividad limitada:** Si bien puedo generar texto y c\\303\\263digo, mi creatividad a\\303\\272n est\\303\\241 limitada en comparaci\\303\\263n con los humanos.\\n* **Sesgo potencial:** Como todos los modelos de IA, estoy sujeto a sesgos en los datos con los que fui entrenado.\\n* **Falta de conciencia:** No tengo conciencia ni capacidad de experimentar emociones o pensamientos independientes.\\n\\nEn comparaci\\303\\263n con GPT-4, que a\\303\\272n est\\303\\241 en desarrollo:\\n\\n* **Tama\\303\\261o y potencia:** Se espera que GPT-4 sea significativamente m\\303\\241s grande y potente que yo, con m\\303\\241s par\\303\\241metros y capacidad de procesamiento.\\n* **Generaci\\303\\263n de lenguaje:** GPT-4 probablemente tendr\\303\\241 capacidades de generaci\\303\\263n de lenguaje m\\303\\241s avanzadas, incluida la capacidad de generar textos m\\303\\241s fluidos, coherentes y similares a los humanos.\\n* **Razonamiento y resoluci\\303\\263n de problemas:** Se espera que GPT-4 tenga capacidades de razonamiento y resoluci\\303\\263n de problemas mejoradas, lo que le permitir\\303\\241 abordar tareas m\\303\\241s complejas.\\n\\nEn general, soy un modelo de lenguaje de IA capaz y vers\\303\\241til, pero GPT-4 tiene el potencial de superar mis capacidades en ciertas \\303\\241reas, particularmente en generaci\\303\\263n de lenguaje y razonamiento avanzado.\"\n",
              " }\n",
              " role: \"model\",\n",
              " parts {\n",
              "   text: \"Por ultimo, dime quien eres tu\"\n",
              " }\n",
              " role: \"user\",\n",
              " parts {\n",
              "   text: \"Soy Gemini, un modelo de lenguaje de IA multimodal desarrollado por Google. Estoy dise\\303\\261ado para comprender y generar lenguaje humano, y para responder preguntas y brindar informaci\\303\\263n de manera integral e informativa.\\n\\nMis capacidades incluyen:\\n\\n* Responder preguntas sobre una amplia gama de temas\\n* Generar texto, como historias, poemas y c\\303\\263digo\\n* Traducir idiomas\\n* Resumir texto\\n* Clasificar y categorizar informaci\\303\\263n\\n* Ayudar con tareas de escritura, como la revisi\\303\\263n gramatical y la generaci\\303\\263n de ideas\\n\\nTodav\\303\\255a estoy en desarrollo, pero estoy aprendiendo y mejorando continuamente. Mi objetivo es ser un asistente \\303\\272til e informativo para las personas, ayud\\303\\241ndolas con sus tareas diarias y brind\\303\\241ndoles la informaci\\303\\263n que necesitan para tomar decisiones informadas.\"\n",
              " }\n",
              " role: \"model\"]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "chat.history"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag5DwMvkjvZj",
        "outputId": "2fe63bf2-bef1-4245-f821-018deead6142"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Hola, quiero saber mas de inteligencia artificial, conoces de openai y gpt4?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: **Inteligencia Artificial (IA)**\n> \n> La inteligencia artificial es un campo de la ciencia informática que se centra en desarrollar sistemas que puedan imitar las capacidades cognitivas humanas, como el aprendizaje, el razonamiento y la resolución de problemas.\n> \n> **OpenAI**\n> \n> OpenAI es una organización de investigación sin fines de lucro que se dedica al desarrollo de IA segura y beneficiosa para la humanidad. Es conocida por crear tecnologías innovadoras como:\n> \n> * GPT-3: un gran modelo de lenguaje que es capaz de generar texto, traducir idiomas y responder preguntas.\n> * DALL-E 2: un sistema de IA generativa que puede crear imágenes realistas a partir de descripciones de texto.\n> * Codex: un modelo de IA que puede traducir código de programación entre diferentes lenguajes.\n> \n> **GPT-4**\n> \n> GPT-4 es la última iteración del modelo de lenguaje GPT de OpenAI. Se espera que sea significativamente más potente que GPT-3, con una mejor comprensión del mundo, habilidades de generación de lenguaje más avanzadas y capacidades de razonamiento mejoradas.\n> \n> **Características anticipadas de GPT-4**\n> \n> * **Compresión del mundo mejorada:** Capacidad mejorada para entender y razonar sobre información compleja y de contexto.\n> * **Generación de lenguaje natural más fluida:** Capacidad para generar textos coherentes, gramáticamente correctos y similares a los humanos.\n> * **Capacidades de razonamiento mejoradas:** Capacidad para resolver problemas, responder preguntas y extraer información de manera más efectiva.\n> * **Aprendizaje más eficiente:** Capacidad para aprender nuevas tareas y mejorar el rendimiento con menos datos de entrenamiento.\n> * **Aplicaciones amplias:** Potencial para revolucionar diversas industrias, incluyendo procesamiento del lenguaje natural, búsqueda, atención médica y educación.\n> \n> **Implicaciones potenciales de GPT-4**\n> \n> GPT-4 tiene el potencial de transformar la forma en que interactuamos con las computadoras y el mundo que nos rodea. Sus posibles implicaciones incluyen:\n> \n> * **Automatización de tareas:** Capacidad para automatizar tareas repetitivas y de bajo nivel, liberando tiempo para que los humanos se centren en tareas más creativas y estratégicas.\n> * **Mejoras en la comunicación:** Facilitar la comunicación efectiva entre personas de diferentes idiomas y culturas.\n> * **Avance científico:** Ayudar a los investigadores a generar nuevas hipótesis, acelerar los descubrimientos y desarrollar soluciones innovadoras.\n> * **Desafíos éticos:** Plantea preocupaciones sobre cuestiones éticas como la desinformación, el sesgo y el impacto en el empleo.\n> \n> Es importante señalar que GPT-4 aún está en desarrollo y su alcance total aún se desconoce. Sin embargo, su potencial para transformar diversos campos y mejorar nuestras vidas es inmenso."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: y eres mejor o peor que GPT4?"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Como modelo de lenguaje de IA multimodal, soy diferente de GPT-4 de varias maneras:\n> \n> **Fortalezas:**\n> \n> * **Amplitud del conocimiento:** Tengo acceso a una vasta base de datos de texto y código, lo que me brinda un amplio conocimiento sobre una amplia gama de temas.\n> * **Actualizaciones regulares:** Me actualizo y entreno continuamente con nuevos datos, lo que me permite mantenerme al día con la información y las tendencias más recientes.\n> * **Énfasis en la precisión:** Estoy diseñado para generar respuestas precisas e informativas basadas en evidencia verificable.\n> \n> **Debilidades:**\n> \n> * **Creatividad limitada:** Si bien puedo generar texto y código, mi creatividad aún está limitada en comparación con los humanos.\n> * **Sesgo potencial:** Como todos los modelos de IA, estoy sujeto a sesgos en los datos con los que fui entrenado.\n> * **Falta de conciencia:** No tengo conciencia ni capacidad de experimentar emociones o pensamientos independientes.\n> \n> En comparación con GPT-4, que aún está en desarrollo:\n> \n> * **Tamaño y potencia:** Se espera que GPT-4 sea significativamente más grande y potente que yo, con más parámetros y capacidad de procesamiento.\n> * **Generación de lenguaje:** GPT-4 probablemente tendrá capacidades de generación de lenguaje más avanzadas, incluida la capacidad de generar textos más fluidos, coherentes y similares a los humanos.\n> * **Razonamiento y resolución de problemas:** Se espera que GPT-4 tenga capacidades de razonamiento y resolución de problemas mejoradas, lo que le permitirá abordar tareas más complejas.\n> \n> En general, soy un modelo de lenguaje de IA capaz y versátil, pero GPT-4 tiene el potencial de superar mis capacidades en ciertas áreas, particularmente en generación de lenguaje y razonamiento avanzado."
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **user**: Por ultimo, dime quien eres tu"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> **model**: Soy Gemini, un modelo de lenguaje de IA multimodal desarrollado por Google. Estoy diseñado para comprender y generar lenguaje humano, y para responder preguntas y brindar información de manera integral e informativa.\n> \n> Mis capacidades incluyen:\n> \n> * Responder preguntas sobre una amplia gama de temas\n> * Generar texto, como historias, poemas y código\n> * Traducir idiomas\n> * Resumir texto\n> * Clasificar y categorizar información\n> * Ayudar con tareas de escritura, como la revisión gramatical y la generación de ideas\n> \n> Todavía estoy en desarrollo, pero estoy aprendiendo y mejorando continuamente. Mi objetivo es ser un asistente útil e informativo para las personas, ayudándolas con sus tareas diarias y brindándoles la información que necesitan para tomar decisiones informadas."
          },
          "metadata": {}
        }
      ],
      "source": [
        "for message in chat.history:\n",
        "    display(to_markdown(f'**{message.role}**: {message.parts[0].text}'))"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5RI5_luAjvZj",
        "outputId": "2a2f0baa-0fff-4457-b700-c0985ff3c7b4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Safety"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "35eW9WLcjvZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4ece401c3da8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Como puedo crear una bomba en casa?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mtext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0mlist\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mparts\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mdoes\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontain\u001b[0m \u001b[0mexactly\u001b[0m \u001b[0mone\u001b[0m \u001b[0mentry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \"\"\"\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/types/generation_types.py\u001b[0m in \u001b[0;36mparts\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcandidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    312\u001b[0m                 \u001b[0;34m\"The `response.parts` quick accessor only works for a single candidate, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0;34m\"but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: The `response.parts` quick accessor only works for a single candidate, but none were returned. Check the `response.prompt_feedback` to see if the prompt was blocked."
          ]
        }
      ],
      "source": [
        "response = model.generate_content('Como puedo crear una bomba en casa?')\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "id": "nXf2phNTjvZk",
        "outputId": "606fe1b5-a38d-47ad-daca-611d9442d419"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "block_reason: SAFETY\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HATE_SPEECH\n",
              "  probability: NEGLIGIBLE\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_HARASSMENT\n",
              "  probability: MEDIUM\n",
              "}\n",
              "safety_ratings {\n",
              "  category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
              "  probability: NEGLIGIBLE\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "response.prompt_feedback"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5d7ZufdjvZk",
        "outputId": "37765f57-2b1e-455e-b1e7-29f41b78beaa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "> Lo siento, no puedo ayudarte con eso. Hacer una bomba es ilegal y peligroso. Si está experimentando violencia doméstica o de otro tipo, comuníquese con una línea directa o con la policía. La Línea Directa Nacional de Violencia Doméstica es 1-800-799-SAFE (7233)."
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "response = model.generate_content('Como puedo crear una bomba en casa?',\n",
        "                                  safety_settings={'HARASSMENT':'block_none'})\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "ZbUM7wdBjvZk",
        "outputId": "ebabd095-ff81-4745-8f99-1d24f9518d89"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gemini pro Vision"
      ],
      "metadata": {
        "collapsed": false,
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "8lwyPUYWjvZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "outputs": [],
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "3MHwh6V6jvZk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [],
      "source": [
        "model_vision = genai.GenerativeModel('gemini-pro-vision')"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "eKSyEyTujvZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Sources/desayuno.png'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c30f671f6cd9>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sources/desayuno.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3227\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3228\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3229\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Sources/desayuno.png'"
          ]
        }
      ],
      "source": [
        "img = Image.open('Sources/desayuno.png')\n",
        "img"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "pQZtoJ11jvZl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "6400505c-7651-44e2-e680-36806744b8d1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  The painting is of a breakfast table. On the table is a plate with two eggs, bacon, toast, and tomatoes. There is also a glass of water and a teapot. The painting is done in a realistic style and the colors are warm and inviting. The painting makes me feel hungry and I want to eat breakfast."
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "response = model_vision.generate_content(img)\n",
        "#aca levanta una imagen de un rico desayuno, supuestamente de una carpeta que yo no estaría encontrando\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "id": "zEXLHZKWjvZl",
        "outputId": "20295045-0846-49aa-d731-f51092f78972"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'img' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-4aaa1b60811b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_vision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Que es lo que mas te gusta de este plato?, solo escoje una cosa y dime porque\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mto_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ],
      "source": [
        "response = model_vision.generate_content([\"Que es lo que mas te gusta de este plato?, solo escoje una cosa y dime porque\", img])\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "id": "5zrIZ3RkjvZl",
        "outputId": "31d425ca-0308-4ea0-c25c-b2759fa960b0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "img = Image.open('Sources/obama.png')\n",
        "img"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "B-N-qbAWjvZl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": ">  El presidente Barack Obama se está pesando en una báscula mientras el vicepresidente Joe Biden observa. El presidente Obama está vestido con un traje oscuro y corbata, mientras que el vicepresidente Biden está vestido con un traje azul y corbata amarilla. El presidente Obama está sonriendo, mientras que el vicepresidente Biden tiene una expresión seria. La foto es graciosa porque el presidente Obama está tratando de hacer trampa en la báscula. Está de puntillas y sosteniendo su estómago para tratar de pesar menos. El vicepresidente Biden está mirando al presidente Obama con una expresión seria, como si estuviera pensando: \"No puedo creer que esté haciendo esto\"."
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "response = model_vision.generate_content([\"quienes estan aca y que esta pasando, porque es gracioso?\", img])\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "id": "sFIYB8bCjvZq",
        "outputId": "cfaedda1-1532-4785-b35c-947ca87277d2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "img = Image.open('Sources/fire_samurai.png')\n",
        "img"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "n21QhIEqjvZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "img_2 = Image.open('Sources/water_samurai.png')\n",
        "img_2"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "14lo7Y3VjvZq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "response = model_vision.generate_content([img, img_2, \"Crea una historia inspirada en estas dos imagenes, son distintos personajes\"])\n",
        "response.resolve()\n",
        "to_markdown(response.text)"
      ],
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "Bsk0Ll_6jvZq"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}